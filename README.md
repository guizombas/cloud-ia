**‚òÅÔ∏è Projeto Cloud Native & Serverless - Assistente de Conversa√ß√£o (Chat-GPT Style)**

Este reposit√≥rio cont√©m a implementa√ß√£o do Trabalho Pr√°tico 2 da disciplina de Arquitetura de Solu√ß√µes Cloud Native & Serverless. O projeto consiste em um servi√ßo de chat inteligente, resiliente e escal√°vel, utilizando uma arquitetura h√≠brida (Serverless + Containers).

## üìã Integrantes

   **Institui√ß√£o:** PUC Minas
  
   **Curso:** Arquitetura de Solu√ß√µes
  
   **Grupo:**
 
    Aline Maria - Matr√≠cula: 234631
   
    Cristiana Elisa - [Inserir Matr√≠cula]
   
    Davi Felipe - Matr√≠cula: 234846
   
    Guilherme Gabriel - [Inserir Matr√≠cula]
  
## üèóÔ∏è Arquitetura da Solu√ß√£o
A solu√ß√£o foi implementada seguindo o desenho arquitetural aprovado no TP1, visando desacoplamento e alta disponibilidade.

**Diagrama de Arquitetura**

<img width="903" height="592" alt="image" src="https://github.com/user-attachments/assets/f4645117-2b04-4123-b72e-4a5a267d2d29" />

(Imagem: Trabalho de Arquitetura de Solu√ß√µes Cloud Native & Serverless.doc)


**Fluxo de Dados**

   **- Entrada:** O cliente (Web) conecta-se via API Gateway.
    
   **- Processamento R√°pido (Serverless):** Fun√ß√µes FaaS (Lambda) recebem a requisi√ß√£o HTTP e a enfileiram no SQS.
    
   **- Processamento Ass√≠ncrono (Worker):** Pods/Containers consomem a fila SQS.
    
   **- Intelig√™ncia:** O Worker chama a API de LLM externa (OpenAI/Anthropic) protegida por um Circuit Breaker.
    
   **- Resposta:** O resultado √© enviado de volta ao cliente via conex√£o WebSocket e persistido no DynamoDB.

## üöÄ Implementa√ß√£o e Componentes (C√≥digo Fonte)

  **1. API Gateway & Entrypoint**
    Tecnologia: [Ex: AWS API Gateway / Kong / Nginx]
    Pol√≠ticas Implementadas:
    Autentica√ß√£o: [Ex: Valida√ß√£o de JWT no Authorizer da Lambda]
    Rate Limiting: [Ex: Limite de 100 req/s por usu√°rio para prote√ß√£o de custos]
    Roteamento: Separa√ß√£o clara entre rotas REST (POST /chat) e rotas WebSocket ($connect, $default).
  
  **2. Compute Layer (H√≠brido)**
    FaaS (Serverless):
    Respons√°vel pela recep√ß√£o de mensagens e gerenciamento de conex√µes WebSocket.
    Localiza√ß√£o no c√≥digo: /src/lambdas 1
    Workers (Containers/Kubernetes):
    Respons√°vel pelo processamento pesado e comunica√ß√£o com a LLM. Utiliza containers para evitar timeouts do FaaS em respostas longas da IA.
    Localiza√ß√£o no c√≥digo: /src/worker 2
  
  **3. Persist√™ncia e Cache**
    DynamoDB (NoSQL): Utilizado para hist√≥rico de chat com padr√£o de acesso hier√°rquico (User -> Chat -> Message)3.
    Redis: Cache de contexto e mapeamento de sess√µes WebSocket (Session ID <-> Connection ID) para baixa lat√™ncia4.

## üõ°Ô∏è Resili√™ncia (Requisito Chave do TP2)
Aplicamos padr√µes de estabilidade para garantir que o sistema suporte falhas em depend√™ncias externas (API da LLM).

  **Mecanisma:** Circuit Breaker
  **Onde foi aplicado?** Worker Service
  **Descri√ß√£o:** Protege o sistema caso a API da OpenAI caia. Se a taxa de erros passar de X%, o circuito abre e falha r√°pido ("Fail Fast") sem consumir recursos5.
  
  **Mecanisma:** Retry com Backoff
  **Onde foi aplicado?** Fila SQS
  **Descri√ß√£o:** Se o processamento falhar, a mensagem retorna √† fila e √© tentada novamente ap√≥s um tempo exponencial, garantindo que perguntas n√£o sejam perdidas6.
  
  **Mecanisma:** Dead Letter Queue (DLQ)
  **Onde foi aplicado?** Infraestrutura SQS
  **Descri√ß√£o:** Mensagens que falham repetidamente s√£o enviadas para uma DLQ para an√°lise posterior.
  
  **Mecanisma:** Timeouts
  **Onde foi aplicado?** Chamadas HTTP
  **Descri√ß√£o:** Timeouts configurados em 29s nas Lambdas e defini√ß√µes r√≠gidas nas chamadas √† API externa.

## üìä Observabilidade
A aplica√ß√£o foi instrumentada para fornecer visibilidade completa do fluxo distribu√≠do (Traces, M√©tricas e Logs).

  **1. Tracing Distribu√≠do**
  Utilizamos [Ex: AWS X-Ray / New Relic / Jaeger] para rastrear a requisi√ß√£o desde o API Gateway, passando pela Fila SQS, at√© o Worker e a volta via WebSocket.
  Evid√™ncia: ![Screenshot do Trace](./docs/trace-exemplo.png)
  
  **3. M√©tricas (Dashboards)**
  Monitoramos as seguintes m√©tricas vitais (Golden Signals):
  Lat√™ncia: Tempo de resposta da LLM.
  Tr√°fego: Quantidade de mensagens na fila SQS.
  Erros: Taxa de falhas no Circuit Breaker.
  Evid√™ncia: ![Dashboard de Monitoramento](./docs/dashboard.png)

## üí∞ CloudOps & FinOps

  **Infraestrutura como C√≥digo (IaC)**
  Toda a infraestrutura foi provisionada via c√≥digo para garantir reprodutibilidade e auditoria7.
    **Ferramenta:** [Ex: Terraform / Serverless Framework / AWS SAM]
    **Pipeline CI/CD:** O deploy √© realizado automaticamente via GitHub Actions8.
  
  **Estrat√©gia de Custos (FinOps)**
    **Scale-to-Zero:** O front-end e a camada de entrada (Lambdas) custam zero quando n√£o utilizados9.
    **Spot Instances:** [Se aplic√°vel] Uso de inst√¢ncias Spot para os Workers no Kubernetes para redu√ß√£o de custos computacionais.

## üõ†Ô∏è Como rodar o projeto localmente
  
 **Pr√©-requisitos**
    Docker & Docker Compose
    Node.js v18+ / Python 3.9+
    Conta configurada na AWS (CLI)

  **Passos**
  1. Clone o reposit√≥rio:
    git clone https://github.com/guizombas/cloud-ia.git
  
  2. Instale as depend√™ncias:
    npm install
  
  3. Deploy da infraestrutura:
    serverless deploy --stage dev

-------------------------------------------------------------------------------------------------------------

## Tolist

Prioridades:
- [x] Criar base para cria√ß√£o de lambdas
- [x] Criar lambda de POST de mensagem (gerar jobId, enviar para fila SQS e salvar connection id no redis)
- [ ] Criar worker pod que l√™ do SQS
- [ ] No worker pod, implementar chamada para a API LLM (passar API_KEY no .env)
- [ ] No worker pod, implementar leitura e escrita de mensagens da conversa no dynamodb
- [ ] No worker pod, implementar retorno no websocket lendo connection id do redis
- [ ] Criar servi√ßo que sobe conex√£o websocket (n√£o tem API Gateway WebSocket no Localstack free)
- [ ] Gerar connectionId e retornar na conex√£o no servi√ßo websocket

Menor prioridade:
- [ ] Usar o parameter store para salvar API_KEY
- [ ] implementar refresh de sess√£o websocket 
- [ ] implementar kubernets local usando helm
- [ ] Criar lambda de GET de mensagens
- [ ] Criar lamda de GET de conversas
- [ ] Implementar cache de mensagens no redis no worker e no 
- [ ] Detalhar readme com arquitetura e diagrama e contexto
- [ ] Criar frontend que faz as chamadas
- [ ] Adicionar instrumenta√ß√£o no newRelic
- [ ] Fazer parte de infra como c√≥digo (terraform)
