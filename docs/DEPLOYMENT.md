# üì¶ Guia de Deployment ‚Äî Projeto Cloud Native & Serverless (cloud-ia)

Este documento descreve o processo de deployment da solu√ß√£o h√≠brida (Serverless + Containers), incluindo a infraestrutura necess√°ria, configura√ß√£o de servi√ßos, pipeline sugerido e instru√ß√µes para ambientes locais e cloud.

---

# üèóÔ∏è 1. Vis√£o Geral do Deployment

A aplica√ß√£o utiliza uma arquitetura que combina:

- **Serverless (FaaS ‚Äì Lambdas)**: entrada HTTP e gerenciamento de sess√µes WebSocket  
- **Containers (Workers)**: processamento ass√≠ncrono, chamadas √† LLM e grava√ß√£o de hist√≥rico  
- **Infraestrutura Gerenciada**:
  - Amazon SQS  
  - DynamoDB  
  - Redis (cache e sess√£o)  
  - API Gateway HTTP (produ√ß√£o)
  - WebSocket Service customizado (ambiente local)
- **IaC (Infrastructure as Code)**: recomenda√ß√£o de uso de Terraform, Serverless Framework ou AWS SAM  
- **CI/CD**: GitHub Actions para automa√ß√£o do pipeline  

---

# ‚öôÔ∏è 2. Componentes Necess√°rios

A solu√ß√£o possui os seguintes componentes na infraestrutura de produ√ß√£o:

## **2.1. API Gateway (HTTP + WebSocket)**
- Rotas REST (ex: `POST /chat`)
- Rotas WebSocket (`$connect`, `$disconnect`, `$default`)
- Autentica√ß√£o (ex: JWT)
- Rate limiting configurado

## **2.2. Fun√ß√µes Serverless (Lambdas)**
Localiza√ß√£o no c√≥digo: `/src/lambdas`

Responsabilidades:
- Receber mensagem do cliente
- Gerar `jobId`
- Enviar mensagens para o SQS
- Registrar `connectionId` no Redis
- Enviar eventos WebSocket via callback

## **2.3. Workers em Containers**
Localiza√ß√£o: `/src/worker`

Executados no Kubernetes (produ√ß√£o) ou Docker (local).

Respons√°veis por:
- Ler mensagens do SQS
- Chamar API da LLM (OpenAI/Anthropic)
- Salvar mensagens no DynamoDB
- Enviar respostas para o WebSocket via Redis

## **2.4. Filas e Mensageria**
- **SQS principal**
- **Dead Letter Queue (DLQ)** configurada
- Visibilidade e backoff configurados

## **2.5. Banco de Dados**
**DynamoDB** com modelo hier√°rquico:



User -> Chat -> Message


## **2.6. Cache e Sess√µes**
**Redis**:
- Mapeamento `sessionId <-> connectionId`
- Cache de contexto de conversa

---

# üõ†Ô∏è 3. Deployment Local (Ambiente de Desenvolvimento)

## **3.1. Pr√©-requisitos**
- Docker & Docker Compose  
- Node.js 18+ (ou Python 3.9+, conforme suas Lambdas)  
- AWS CLI configurado  
- Serverless Framework ou AWS SAM instalado  
- Redis local (Docker)  
- DynamoDB local (opcional)

## **3.2. Passos**

### **1Ô∏è‚É£ Clonar o reposit√≥rio**
```bash
git clone https://github.com/guizombas/cloud-ia.git
cd cloud-ia
```

### **2Ô∏è‚É£ Instalar depend√™ncias
```bash
npm install
```

### **3Ô∏è‚É£ #Subir servi√ßos auxiliares (Redis, Worker, WebSocket)

No ambiente local n√£o h√° API Gateway WebSocket.
Portanto, um servi√ßo pr√≥prio WebSocket deve ser iniciado.

Um docker-compose.yml deve conter ao menos:

- redis

- worker

- websocket-service

### **4Ô∏è‚É£ Deploy das Lambdas

Caso use Serverless Framework:
```bash
serverless deploy --stage dev
```

Isso criar√°:

Lambda POST /chat

Policies IAM

Fila SQS

DLQ

API Gateway HTTP

### **5Ô∏è‚É£ Verificar endpoints criados

Exemplo:

```bash
serverless info
```

### **‚òÅÔ∏è 4. Deployment em Produ√ß√£o (AWS)
#4.1. Infraestrutura como C√≥digo (IaC)

# Ferramentas recomendadas:

- Terraform (para a parte AWS + Kubernetes)
- Serverless Framework (para as Lambdas + API Gateway)
- Helm (para deploy no EKS)

# Componentes provisionados via IaC:

- SQS + DLQ
- DynamoDB
- Redis (Elasticache)
- Roles IAM (Lambdas e Workers)
- API Gateway REST + WebSocket
- Lambdas (upload + config)
- Cluster Kubernetes (EKS)
- Worker Deployment + HPA
- Secrets (API_KEY da LLM)

### **üöÄ 5. Pipeline de CI/CD (GitHub Actions)

Um workflow sugerido:

# 5.1. Para Lambdas

Pipeline:

- Rodar lint/testes
- Empacotar Lambdas
- Deploy via Serverless Framework

# 5.2. Para Workers

Pipeline:

- Build da imagem Docker
- Push no ECR
- Apply do Helm Chart no EKS

### **üß™ 6. Testes P√≥s-Deploy

Ap√≥s o deploy, validar:

# API HTTP

```bash
curl -X POST https://<api-gateway-url>/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Ol√°"}'
```

# WebSocket

Conectar usando:

```bash
wscat -c ws://<ws-endpoint>
```

# SQS

Verificar se:

mensagens entram na fila

# DLQ est√° vazia

# Worker Pod

```bash
kubectl logs deployment/worker
```
# DynamoDB

Verificar hist√≥rico no console AWS ou via CLI.

### **üß∞ 7. Troubleshooting
# Mensagens n√£o chegam ao Worker

- Verificar permiss√µes IAM
- Verificar se Worker est√° consumindo da fila certa
- Verificar visibilityTimeout
- WebSocket n√£o responde
- Verificar salvamento do connectionId no Redis
- Verificar timeout de sess√£o
- Circuit Breaker ativando demais
- Confirmar limites de erro da API externa
- Verificar lat√™ncia da LLM

### **üìå 8. Roadmap (Relacionado ao Deployment)
# Prioridade Alta

- Criar WebSocket Service pr√≥prio para ambiente local
- Criar Lambda POST /chat
- Criar Worker para ler SQS
- Configurar integra√ß√£o com LLM
- Configurar DynamoDB + Redis

# Prioridade Baixa

- Parameter Store para secrets
- Deploy Kubernetes com Helm local
- Lambdas GET (mensagens + conversas)
- Frontend SPA
- Instrumenta√ß√£o New Relic
- Terraform para toda infraestrutura

### **‚úîÔ∏è 9. Conclus√£o

Este documento descreve o processo de deployment completo da solu√ß√£o Cloud Native & Serverless.
Com ele, o time consegue:

- Executar localmente
- Fazer deploy em cloud
- Automatizar via CI/CD
- Operar e diagnosticar problemas
- Adicionar novas funcionalidades com seguran√ßa


