# Observabilidade e Monitoramento ‚Äî Cloud-IA

Este documento descreve a estrat√©gia de **Observabilidade** do projeto cloud-ia.
Devido √† natureza ass√≠ncrona e distribu√≠da da arquitetura (Serverless + Filas + Containers), a observabilidade n√£o √© opcional, mas mandat√≥ria para entender o fluxo completo da requisi√ß√£o e garantir a estabilidade operacional.

---

## ‚òÅÔ∏è 1. O Desafio de Rastreamento (Distributed Tracing)

Nesta arquitetura, uma requisi√ß√£o de chat n√£o come√ßa e termina no mesmo servi√ßo de forma s√≠ncrona. Ela atravessa barreiras onde o contexto pode ser perdido facilmente:

1.  **FaaS HTTP:** Recebe o POST e retorna `202 Accepted` (o cliente "solta" a conex√£o HTTP).
2.  **SQS:** A mensagem fica "em repouso" na fila aguardando processamento.
3.  **Worker:** Processa a mensagem, recupera contexto e chama a LLM.
4.  **WebSocket:** Entrega a resposta ao cliente em outro canal.

Sem uma estrat√©gia de **Rastreamento Distribu√≠do**, os logs ficam isolados e √© imposs√≠vel saber se a lentid√£o ocorreu na fila (falta de workers), no processamento (c√≥digo lento) ou na API externa (OpenAI).

---

## üöÄ 2. Ferramentas da Stack

A stack de observabilidade planejada √© composta por:

* **AWS CloudWatch:** Logs brutos de Lambdas, m√©tricas nativas de fila SQS e alarmes de infraestrutura b√°sica.
* **New Relic (APM & Tracing):** Ferramenta principal para correlacionar os servi√ßos e visualizar o trace completo (*End-to-End*).
* **Logs Estruturados (JSON):** Padr√£o de escrita de log para facilitar a ingest√£o e busca automatizada.

---

## ‚û°Ô∏è 3. Estrat√©gia de Correla√ß√£o (Trace ID)

Para unir os logs de componentes distintos, todo o fluxo deve compartilhar um identificador √∫nico.

### 3.1. O Fluxo do `traceId`

1.  **Gera√ß√£o:** O Frontend envia (ou a Lambda `POST /chat` gera) um `traceId` √∫nico (UUID) no in√≠cio da requisi√ß√£o. O `jobId` tamb√©m pode atuar como identificador de neg√≥cio.
2.  **Propaga√ß√£o:**
    * **Lambda -> SQS:** O `traceId` √© injetado nos `MessageAttributes` da mensagem SQS.
    * **SQS -> Worker:** O Worker extrai o `traceId` dos atributos antes de iniciar o processamento.
    * **Worker -> Logs:** Todo log gerado pelo Worker deve conter esse ID.
    * **Worker -> WebSocket:** A resposta final inclui o ID para que o Frontend possa medir a lat√™ncia total (Time to First Token).

---

## ‚ú® 4. M√©tricas Chave (Golden Signals)

Monitoramos quatro categorias principais de m√©tricas para garantir a sa√∫de do sistema.

### 4.1. Lat√™ncia (Performance)
Precisamos saber onde o tempo est√° sendo gasto:
* **SQS Dwell Time (Age of Message):** Quanto tempo a mensagem ficou parada na fila esperando um Worker? (M√©trica cr√≠tica para *Auto-scaling*).
* **Worker Processing Time:** Tempo total de execu√ß√£o do script de neg√≥cio.
* **LLM Response Time:** Lat√™ncia pura da API da OpenAI/Anthropic (fator externo).

### 4.2. Tr√°fego (Throughput)
* **RPM:** Requisi√ß√µes por minuto no endpoint `/chat`.
* **MPS:** Mensagens processadas por segundo pelos Workers.
* **Conex√µes Ativas:** N√∫mero de clientes conectados no WebSocket simultaneamente.

### 4.3. Erros (Confiabilidade)
* **Circuit Breaker State:** Monitorar transi√ß√µes para o estado `OPEN`. Isso indica falha massiva na IA externa.
* **DLQ Depth:** Quantidade de mensagens na *Dead Letter Queue*. Deve ser sempre zero. Se subir, indica bugs ou dados inv√°lidos.
* **Taxa de Erros 4xx/5xx:** No API Gateway e nas chamadas √† LLM.

### 4.4. M√©tricas de Neg√≥cio (FinOps)
Dados para cruzar performance t√©cnica com impacto financeiro:
* **Tokens por Minuto:** Consumo de tokens da LLM (custo direto).
* **Custo por Job:** M√©dia de custo baseada no tamanho do contexto.

---

## üìö 5. Padr√£o de Logs (Structured Logging)

Para facilitar a busca no CloudWatch ou New Relic, os logs **n√£o devem ser texto puro**, mas sim objetos JSON.

**Exemplo de Log de Sucesso no Worker:**
```json
{
  "level": "info",
  "timestamp": "2025-12-10T14:30:00Z",
  "service": "worker-chat",
  "traceId": "abc-123-xyz",
  "jobId": "job-999",
  "action": "llm_request_success",
  "duration_ms": 1540,
  "metadata": {
    "model": "gpt-4",
    "tokens_input": 50,
    "tokens_output": 100
  }
}
```
**Exemplo de Log de Erro (Circuit Breaker):**
```json
{
  "level": "error",
  "timestamp": "2025-12-10T14:31:00Z",
  "service": "worker-chat",
  "traceId": "def-456-uvw",
  "alert_type": "circuit_breaker_open",
  "reason": "High failure rate from LLM provider",
  "failure_count": 5
}
```

---

## ‚ö° 6. Alertas e Alarmes (SRE)

Defini√ß√£o de gatilhos para acionamento da equipe de engenharia.

|Severidade | M√©trica	| Limite (Threshold)| A√ß√£o Recomendada|
| :--- | :---: | :---: | ---: |
| **CR√çTICA**	| DLQ Depth	| > 0 mensagens	| Interven√ß√£o manual imediata. Risco de perda de dados. |
| **ALTA**	| Circuit Breaker |	Status = Open |	Investigar status da OpenAI. O sistema est√° degradado. |
| **M√âDIA**	| SQS Age |	> 10 segundos |	Sistema lento. Verificar necessidade de escalar mais Workers. |
| **BAIXA**	| Erro 4xx |	> 5% total	| Investigar poss√≠vel bug no Frontend ou Payload inv√°lido. |

---

## üó∫Ô∏è 7. Roadmap de Observabilidade

- [ ] Implementar logs estruturados JSON b√°sicos (CloudWatch).
- [ ] Garantir propaga√ß√£o do traceId (Lambda -> SQS -> Worker).
- [ ] **v1.4.0:** Adicionar instrumenta√ß√£o completa com Agente New Relic e cria√ß√£o de Dashboards unificados.
